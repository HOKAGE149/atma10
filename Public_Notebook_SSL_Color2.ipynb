{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Public_Notebook_SSL_Color2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"7dc157a559d24d17a7d8f191dbdce491":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_623265245f0e4e49831db7352aaf466b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a96b9891ba924cb39414360d5afbf920","IPY_MODEL_bc8dcb7c88be44268689191a7e49c20d"]}},"623265245f0e4e49831db7352aaf466b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a96b9891ba924cb39414360d5afbf920":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_387f5d1a7a604ebf8dcd50b6ef3aa1c5","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":23995,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":23995,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6a12e220d6fc44c2b88ce026b8b50616"}},"bc8dcb7c88be44268689191a7e49c20d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2714e265cd7647f0b526302c3534b3db","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 23995/23995 [00:26&lt;00:00, 911.07it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6881f69720d64a6b87b25f7da4c4a103"}},"387f5d1a7a604ebf8dcd50b6ef3aa1c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6a12e220d6fc44c2b88ce026b8b50616":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2714e265cd7647f0b526302c3534b3db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6881f69720d64a6b87b25f7da4c4a103":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8PU5NI3TjZfi"},"source":["## はじめに\n","\n","このノートブックでは自己教師あり対照学習(Self-Supervised Contrastive Learning)を用いて`palette.csv`(`color.csv`にも適用可能)を固定長のベクトルに変換する手法を紹介します。ここで紹介する内容はGPUがないと時間が大幅にかかってしまうため若干手が出しづらいかもしれないことをご承知おきください。\n","\n","なお、今回の内容はどちらかというと興味ドリブンでやってみた系のお話なのでハードルが高い割にスコアにはあまり響かないかもしれません。一応、私の手元の実験ではCVが1.014 → 1.006、LBが0.9876 → 0.9847とCV,LBの両方に寄与しました。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSJVI7BPuBnb","executionInfo":{"status":"ok","timestamp":1616168113760,"user_tz":-540,"elapsed":23827,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"ead0f321-ba30-4fc8-8580-cad1a59419ab"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tEsD80oduDrD","executionInfo":{"status":"ok","timestamp":1616164565498,"user_tz":-540,"elapsed":27526,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"564680c4-5c9b-496d-b299-296980e48852"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/second_take"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/second_take\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4YChayAHkxiZ","executionInfo":{"status":"ok","timestamp":1616164571364,"user_tz":-540,"elapsed":33373,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"2af04587-f3b3-4099-f122-2f873e258726"},"source":["!pip install catalyst"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting catalyst\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/09/70a1474c1ed1415f022ee81bdae54fb0bdfb7cc17229473c2455bcb6c042/catalyst-21.3-py2.py3-none-any.whl (450kB)\n","\u001b[K     |████████████████████████████████| 460kB 5.6MB/s \n","\u001b[?25hCollecting tensorboardX>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n","\u001b[K     |████████████████████████████████| 317kB 7.9MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from catalyst) (1.8.0+cu101)\n","Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/dist-packages (from catalyst) (1.19.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from catalyst) (3.13)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=2.1.0->catalyst) (3.12.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=2.1.0->catalyst) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->catalyst) (3.7.4.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX>=2.1.0->catalyst) (54.0.0)\n","Installing collected packages: tensorboardX, catalyst\n","Successfully installed catalyst-21.3 tensorboardX-2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GaVcU3K1t5ec"},"source":["# from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# checkpoint = ModelCheckpoint(filepath = './model_temp/model_001.h5',\n","#                              monitor='loss',\n","#                              save_best_only=True,\n","#                              save_weight_only=False,\n","#                              mode='min',\n","#                              save_freq=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JdUxil3Rj176","executionInfo":{"status":"ok","timestamp":1616164583215,"user_tz":-540,"elapsed":45202,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"2866a14d-70a7-43b2-a058-92ea6a499b51"},"source":["!pip install -U git+https://github.com/albu/albumentations > /dev/null "],"execution_count":null,"outputs":[{"output_type":"stream","text":["  Running command git clone -q https://github.com/albu/albumentations /tmp/pip-req-build-dzuuy0ly\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j6o1RKIDjZfq"},"source":["import os\n","import random\n","\n","import albumentations as A\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as torchdata\n","import umap\n","\n","from pathlib import Path\n","\n","from albumentations.pytorch import ToTensorV2\n","# from albumentations.pytorch import ToTensor\n","from catalyst.dl import SupervisedRunner, Runner\n","from catalyst.core import Callback, CallbackOrder, IRunner\n","from sklearn.model_selection import KFold\n","from tqdm.notebook import tqdm\n","from tensorflow.keras.callbacks import ModelCheckpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRFLP5nnjZfr"},"source":["sns.set_context(\"talk\")\n","plt.style.use(\"ggplot\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o8VJ3oIkjZfr"},"source":["## モチベーション\n","\n","今回与えられたデータには`palette.csv`や`color.csv`のように作品中の配色の比率を示したデータも与えられており、[パレットの可視化](https://www.guruguru.science/competitions/16/discussions/0cf48a1f-59fd-45b1-880a-cf9fc54d6912/)などでも議論されているように色のバリエーションや鮮やかさなどは予測対象の`likes`とも相関が高そうです。しかしながら一つの作品(`object_id`)に与えられている色の種類はさまざまでこれをうまく固定長の特徴表現に直すのは人手ではなかなか難しそうです。"]},{"cell_type":"code","metadata":{"id":"GMHaAPZbjfZo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dMGk30O7k_7R"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"eNgCSN8ujZfs","executionInfo":{"status":"ok","timestamp":1616164611378,"user_tz":-540,"elapsed":73331,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"1f96cbdc-8826-4ba8-a46a-5133400fd7f2"},"source":["DATADIR = Path(\"./input/\")\n","\n","palette = pd.read_csv(DATADIR / \"palette.csv\")\n","palette.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ratio</th>\n","      <th>color_r</th>\n","      <th>color_g</th>\n","      <th>color_b</th>\n","      <th>object_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.013781</td>\n","      <td>40</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>000405d9a5e3f49fc49d</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.040509</td>\n","      <td>221</td>\n","      <td>189</td>\n","      <td>129</td>\n","      <td>000405d9a5e3f49fc49d</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.036344</td>\n","      <td>207</td>\n","      <td>175</td>\n","      <td>117</td>\n","      <td>000405d9a5e3f49fc49d</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.033316</td>\n","      <td>230</td>\n","      <td>197</td>\n","      <td>129</td>\n","      <td>000405d9a5e3f49fc49d</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.039600</td>\n","      <td>194</td>\n","      <td>161</td>\n","      <td>106</td>\n","      <td>000405d9a5e3f49fc49d</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      ratio  color_r  color_g  color_b             object_id\n","0  0.013781       40        4        0  000405d9a5e3f49fc49d\n","1  0.040509      221      189      129  000405d9a5e3f49fc49d\n","2  0.036344      207      175      117  000405d9a5e3f49fc49d\n","3  0.033316      230      197      129  000405d9a5e3f49fc49d\n","4  0.039600      194      161      106  000405d9a5e3f49fc49d"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"BP48Cj1UjZfu"},"source":["これを踏まえ、[`palette`をまず画像化し](https://www.guruguru.science/competitions/16/discussions/eb65c133-a5e9-43b9-b046-8b6a7184ad5e/)、[学習済みCNNの重みをファインチューンする形で今回のタスクに利用](https://www.guruguru.science/competitions/16/discussions/88babff4-5383-4da4-9496-10b8f1ccad30/)したり、[学習済みCNNを用いて特徴ベクトルに変換](https://www.guruguru.science/competitions/16/discussions/cccaada9-b29b-46d6-93d9-01d992362ce1/)してLightGBMなどで利用する、などの取組が既に紹介されています。\n","\n","しかし、このやり方ではまず`palette.csv`をグラデーションのある画像のように変換する、という手順によって色という情報の他に、「縦に線が入っている」・「左から右にかけて徐々に領域が狭くなる」といった人間が後から処理の都合で付け加えた情報も入るためモデルがこれらの実際は意味のない情報も含めてベクトル化してしまっている可能性もあります。\n","\n","実際には色の比率の情報のみが含まれるため、その配置に関してはランダムでも全く問題はないはずです。実際に各色を`palette.csv`に指示されている比率に従ってランダムに配置した場合はどうなるかみてみましょう。"]},{"cell_type":"markdown","metadata":{"id":"Y8AiCaU_jZfu"},"source":["まず少しトリッキーですが、`palette`の`ratio`をパーセント表示に直した上で四捨五入した整数に直しておきます。その上で`object_id`で集約した時に足し合わせてちょうど100になるようにします。これは後ほど画像化するときに和がちょうど100であると都合がいいからです。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UY26nPKOjZfv","executionInfo":{"status":"ok","timestamp":1616164614996,"user_tz":-540,"elapsed":76923,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"696ad405-1943-44f0-8985-c866cb420096"},"source":["# パーセント表示に直して四捨五入\n","palette[\"ratio_int\"] = palette[\"ratio\"].map(lambda x: int(np.round(10000 * x)))\n","\n","# `object_id`で集約してratio_intを足し合わせると100を超えたり100に満たない場合がある\n","palette.groupby(\"object_id\")[\"ratio_int\"].sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["object_id\n","000405d9a5e3f49fc49d     9998\n","001020bd00b149970f78     9998\n","0011d6be41612ec9eae3    10001\n","0012765f7a97ccc3e9e9    10002\n","00133be3ff222c9b74b0    10001\n","                        ...  \n","fff4bbb55fd7702d294e    10000\n","fffbe07b997bec00e203    10000\n","fffd1675758205748d7f    10001\n","fffd43b134ba7197d890     9998\n","ffff22ea12d7f99cff31     9999\n","Name: ratio_int, Length: 23995, dtype: int64"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["7dc157a559d24d17a7d8f191dbdce491","623265245f0e4e49831db7352aaf466b","a96b9891ba924cb39414360d5afbf920","bc8dcb7c88be44268689191a7e49c20d","387f5d1a7a604ebf8dcd50b6ef3aa1c5","6a12e220d6fc44c2b88ce026b8b50616","2714e265cd7647f0b526302c3534b3db","6881f69720d64a6b87b25f7da4c4a103"]},"id":"Wau_Jbt6jZfv","executionInfo":{"status":"ok","timestamp":1616164649890,"user_tz":-540,"elapsed":111787,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"3dfa353c-bbf6-4e38-a041-d460c66ea3ac"},"source":["# `object_id`で集約した時に足し合わせてちょうど100になるようにする\n","palette_group_dfs = []\n","for _, df in tqdm(palette.groupby(\"object_id\"),\n","                  total=palette[\"object_id\"].nunique()):\n","    # 足し合わせた和が100を超過する場合\n","    if df[\"ratio_int\"].sum() > 10000:\n","        n_excess = df[\"ratio_int\"].sum() - 10000\n","        # ちょっと雑だが一番比率が多い色の割合を減らすことで和を100に揃える\n","        max_ratio_int_idx = df[\"ratio_int\"].idxmax()\n","        df.loc[max_ratio_int_idx, \"ratio_int\"] -= n_excess\n","    elif df[\"ratio_int\"].sum() < 10000:\n","        n_lack = 10000 - df[\"ratio_int\"].sum()\n","        max_ratio_int_idx = df[\"ratio_int\"].idxmax()\n","        df.loc[max_ratio_int_idx, \"ratio_int\"] += n_lack\n","    else:\n","        pass\n","    palette_group_dfs.append(df)\n","    \n","new_palette = pd.concat(palette_group_dfs, axis=0).reset_index(drop=True)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7dc157a559d24d17a7d8f191dbdce491","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=23995.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvmF6vetjZfw","executionInfo":{"status":"ok","timestamp":1616164649996,"user_tz":-540,"elapsed":111871,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"f773f031-7efa-4445-8bd0-41a553d75baa"},"source":["# `object_id`で集約してratio_intを足し合わせるとちょうど100になる\n","new_palette.groupby(\"object_id\")[\"ratio_int\"].sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["object_id\n","000405d9a5e3f49fc49d    10000\n","001020bd00b149970f78    10000\n","0011d6be41612ec9eae3    10000\n","0012765f7a97ccc3e9e9    10000\n","00133be3ff222c9b74b0    10000\n","                        ...  \n","fff4bbb55fd7702d294e    10000\n","fffbe07b997bec00e203    10000\n","fffd1675758205748d7f    10000\n","fffd43b134ba7197d890    10000\n","ffff22ea12d7f99cff31    10000\n","Name: ratio_int, Length: 23995, dtype: int64"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"HeRBRf-njZfw"},"source":["さて、この`new_palette`を使って10x10の画像で各ピクセルが指示された比率だけ指示された色になったような画像をランダムに生成してみます。"]},{"cell_type":"code","metadata":{"id":"uGyQC_WQjZfx"},"source":["def _create_random_image(sample: pd.DataFrame) -> np.ndarray:\n","    \"\"\"\n","    配置はランダムで色の比率がsampleで指示された値になるようにした\n","    10x10の画像を生成する\n","    \"\"\"\n","    # まず一次元で定義しておく\n","    image = np.zeros((10000, 3), dtype=np.uint8)\n","    # sampleの頭から1行ずつその行の色をその行のratio_int分だけコピーして画像を埋める\n","    head = 0\n","    for i, row in sample.iterrows():\n","        # sampleの行に書かれた色\n","        patch = np.array([[row.color_r, row.color_g, row.color_b]], dtype=np.uint8)\n","        # sampleの行に書かれたratio_int分だけコピーする\n","        patch = np.tile(patch, row.ratio_int).reshape(row.ratio_int, -1)\n","        # 画像を上の手順で出した色で埋める\n","        image[head:head + row.ratio_int, :] = patch\n","        head += row.ratio_int\n","    # 乱数で順番をランダム化する\n","    indices = np.random.permutation(np.arange(10000))\n","    image = image[indices, :].reshape(100, 100, 3)\n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I5xeMw9sjZfx"},"source":["この関数で何枚か画像を生成してみましょう。"]},{"cell_type":"markdown","metadata":{"id":"O2m2clcl8yBj"},"source":["## 一旦copastaの関数を記述"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pLO6CRtr8PEv","executionInfo":{"status":"ok","timestamp":1616164650122,"user_tz":-540,"elapsed":111970,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"e368d41b-9a7b-43fa-907e-a6c780013494"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/second_take/src"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/second_take/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"826OEWms8MgO"},"source":["#===========================================================\n","# Config\n","#===========================================================\n","\n","#===========================================================\n","# Config\n","#===========================================================\n","import yaml\n","\n","with open('./config.yaml') as file:\n","    config = yaml.safe_load(file.read())\n","\n","config\n","\n","df_path_dict = {\n","    'train': config['input_dir_root_jn']+'train.csv',\n","    'test': config['input_dir_root_jn']+'test.csv',\n","    'sample_submission': config['input_dir_root_jn']+'sample_submission.csv',\n","    'folds': config['input_dir_jn']+'folds.csv',\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wVVfDT9Z8ayo","executionInfo":{"status":"ok","timestamp":1616164650848,"user_tz":-540,"elapsed":112652,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"7de8f95a-d514-4b48-d563-c5ecc515058b"},"source":["#===========================================================\n","# Library\n","#===========================================================\n","\n","import gc\n","import itertools\n","import json\n","import os\n","import random\n","import sys\n","import time\n","import warnings\n","from collections import Counter, defaultdict\n","from contextlib import contextmanager\n","from functools import partial\n","from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","import builtins\n","import types\n","\n","import lightgbm as lgb\n","import matplotlib.pyplot as plt\n","#import MeCab\n","# # import mojimoji\n","# import neologdn\n","import numpy as np\n","import pandas as pd\n","import scipy as sp\n","import seaborn as sns\n","import torch\n","import xgboost as xgb\n","# from catboost import CatBoostClassifier, CatBoostRegressor\n","from gensim.models.word2vec import Word2Vec\n","from sklearn import preprocessing\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.decomposition import NMF, PCA, TruncatedSVD\n","from sklearn.feature_extraction.text import (CountVectorizer, TfidfVectorizer,\n","                                             _document_frequency)\n","from sklearn.metrics import mean_squared_error, roc_auc_score\n","from sklearn.model_selection import (GroupKFold, GroupShuffleSplit, KFold,\n","                                     StratifiedKFold)\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.utils.validation import check_is_fitted\n","from tqdm.notebook import tqdm\n","from PIL import ImageColor\n","\n","\n","\n","from pathlib import Path\n","\n","from gensim.models import word2vec, KeyedVectors\n","from tqdm import tqdm\n","\n","# import texthero as hero\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.pipeline import Pipeline\n","\n","import nltk\n","\n","nltk.download('stopwords')\n","os.listdir(os.path.expanduser('~/nltk_data/corpora/stopwords/'))\n","\n","class AbstractBaseBlock:\n","    def fit(self, input_df: pd.DataFrame, y=None):\n","        return self.transform(input_df)\n","    \n","    def transform(self, input_df: pd.DataFrame) -> pd.DataFrame:\n","        raise NotImplementedError()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJO70R3W79hr"},"source":["#===========================================================\n","# Utils\n","#===========================================================\n","\n","def seed_everything(seed=1996):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","\n","@contextmanager\n","def timer(name):\n","    t0 = time.time()\n","    logger.info(f'[{name}] start')\n","    yield\n","    logger.info(f'[{name}] done in {time.time() - t0:.0f} s')\n","    logger.info('')\n","\n","\n","def get_logger(filename='log'):\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\", mode='w')\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","logger = get_logger(config['output_dir_jn']+config['fname_log_pp'])\n","\n","def load_df(path, df_name, config):\n","    if path.split('.')[-1]=='csv':\n","        if config['debug']:\n","            df = pd.read_csv(path, nrows=1000)\n","        else:\n","            df = pd.read_csv(path)\n","    elif path.split('.')[-1]=='pkl':\n","        df = pd.read_pickle(path)\n","    logger.info(f\"{df_name} shape / {df.shape} \")\n","    return df\n","\n","def reduce_mem_usage(df, verbose=True):\n","    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n","    start_mem = df.memory_usage().sum() / 1024**2    \n","    for col in df.columns:\n","        col_type = df[col].dtypes\n","        if col_type in numerics:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)  \n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)    \n","    end_mem = df.memory_usage().sum() / 1024**2\n","    if verbose:\n","        logger.info('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n","    return df\n","\n","\n","\n","def imports():\n","    for name, val in globals().items():\n","        # module imports\n","        if isinstance(val, types.ModuleType):\n","            yield name, val\n","\n","            # functions / callables\n","        if hasattr(val, '__call__'):\n","            yield name, val\n","\n","\n","def noglobal(f):\n","    return types.FunctionType(f.__code__,\n","                              dict(imports()),\n","                              f.__name__,\n","                              f.__defaults__,\n","                              f.__closure__\n","                              )\n","\n","\n","\n","\n","# https://github.com/nyk510/vivid/blob/master/vivid/utils.py\n","\n","def decorate(s: str, decoration=None):\n","    if decoration is None:\n","        decoration = '★' * 20\n","        \n","    return ' '.join([decoration, str(s), decoration])\n","\n","class Timer:\n","    def __init__(self, logger=None, format_str='{:.3f}[s]', prefix=None, suffix=None, sep=' ', verbose=0):\n","\n","        if prefix: format_str = str(prefix) + sep + format_str\n","        if suffix: format_str = format_str + sep + str(suffix)\n","        self.format_str = format_str\n","        self.logger = logger\n","        self.start = None\n","        self.end = None\n","        self.verbose = verbose\n","\n","    @property\n","    def duration(self):\n","        if self.end is None:\n","            return 0\n","        return self.end - self.start\n","\n","    def __enter__(self):\n","        self.start = time.time()\n","\n","    def __exit__(self, exc_type, exc_val, exc_tb):\n","        self.end = time.time()\n","        if self.verbose is None:\n","            return\n","        out_str = self.format_str.format(self.duration)\n","        if self.logger:\n","            self.logger.info(out_str)\n","        else:\n","            print(out_str)\n","    \n","\n","def run_blocks(input_df, blocks, y=None, test=False):\n","    out_df = pd.DataFrame()\n","    \n","    print(decorate('start run blocks...'))\n","\n","    with Timer(prefix='run test={}'.format(test)):\n","        for block in feature_blocks:\n","            with Timer(prefix='\\t- {}'.format(str(block))):\n","                if not test:\n","                    out_i = block.fit(input_df, y=y)\n","                else:\n","                    out_i = block.transform(input_df)\n","\n","            assert len(input_df) == len(out_i), block\n","            name = block.__class__.__name__\n","            out_df = pd.concat([out_df, out_i.add_suffix(f'_{name}')], axis=1)\n","        \n","    return out_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SbDFt0Ji7rhT","executionInfo":{"status":"ok","timestamp":1616164654232,"user_tz":-540,"elapsed":116009,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"8de4bf72-713a-42c2-9010-c69cfa5a409d"},"source":["with timer('Data Loading'):\n","    train = load_df(path=df_path_dict['train'], df_name='train', config=config)\n","    test = load_df(path=df_path_dict['test'], df_name='test', config=config)\n","    sample_submission = load_df(path=df_path_dict['sample_submission'], df_name='sample_submission', config=config)\n","    folds = load_df(path=df_path_dict['folds'], df_name='folds', config=config)\n","    gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Data Loading] start\n","train shape / (12026, 19) \n","test shape / (12008, 18) \n","sample_submission shape / (12008, 1) \n","folds shape / (12026, 3) \n","[Data Loading] done in 2 s\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dd2OARSm9D_f","executionInfo":{"status":"ok","timestamp":1616164654233,"user_tz":-540,"elapsed":115993,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"3dab7c17-99e0-4116-d876-45ac9e70f2ed"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/second_take"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/second_take\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OBJvGCbt9MeQ"},"source":["train = train[['object_id', 'likes']]\n","test = test[['object_id']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J-2XbfuF9YKv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fUKcJySVKE8g"},"source":["# データ作成"]},{"cell_type":"code","metadata":{"id":"-gPoOoiYNMGF"},"source":["# unique_object_ids = train[\"object_id\"].unique()\n","# #unique_object_ids = test[\"object_id\"].unique()\n","# unique_palette_obj = new_palette[\"object_id\"].unique()\n","# N_IMAGES_FOR_OBJ_ID = 5\n","# N_OBJ_IDS = len(unique_object_ids)\n","# train_X = []\n","\n","# # fig, axes = plt.subplots(nrows=N_OBJ_IDS, ncols=N_IMAGES_FOR_OBJ_ID, figsize=(25, 25))\n","# for i in tqdm(range(N_OBJ_IDS)):\n","#     obj_id = unique_object_ids[i]\n","#     palette_obj_id = new_palette.query(f\"object_id == '{obj_id}'\")\n","#     #print(obj_id)\n","#     if obj_id not in unique_palette_obj:\n","#       print(_create_random_image(palette_obj_id))\n","#       print(palette_obj_id)\n","#       break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7BNAPybOnJQk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616164881600,"user_tz":-540,"elapsed":343334,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"d2698c97-8b6d-4ad8-f3ae-beb10b83d143"},"source":["unique_object_ids = train[\"object_id\"].unique()\n","N_IMAGES_FOR_OBJ_ID = 1\n","N_OBJ_IDS = len(unique_object_ids)\n","unique_palette_obj = new_palette[\"object_id\"].unique()\n","train_X = []\n","\n","# fig, axes = plt.subplots(nrows=N_OBJ_IDS, ncols=N_IMAGES_FOR_OBJ_ID, figsize=(25, 25))\n","for i in tqdm(range(N_OBJ_IDS)):\n","    obj_id = unique_object_ids[i]\n","    if obj_id not in unique_palette_obj:\n","      continue\n","\n","    palette_obj_id = new_palette.query(f\"object_id == '{obj_id}'\")\n","    #axes[i, 0].set_ylabel(obj_id)\n","    for j in range(N_IMAGES_FOR_OBJ_ID):\n","        generated = _create_random_image(palette_obj_id)\n","        train_X.append(generated)\n","        #axes[i, j].imshow(generated)\n","        #axes[i, j].grid(False)\n","        #axes[i, j].set_title(f\"Generated Image {j}\")\n","        \n","#plt.tight_layout()\n","#plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 12026/12026 [03:48<00:00, 52.70it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"g4lLlwCmPQAr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PBDaf7559_M","executionInfo":{"status":"ok","timestamp":1616164881898,"user_tz":-540,"elapsed":343613,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"24c74596-1271-4bc2-b6bc-09b815d8f159"},"source":["np.array(train_X).shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12007, 100, 100, 3)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"75_OGyk2L1RH"},"source":["import os, zipfile, io, re\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from keras.applications.xception import Xception\n","from keras.models import Model, load_model\n","from keras.layers.core import Dense\n","from keras.layers.pooling import GlobalAveragePooling2D\n","from keras.optimizers import Adam, RMSprop, SGD\n","from keras.utils.np_utils import to_categorical\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.metrics import mean_squared_log_error"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKYqbCfSK9YC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616164888456,"user_tz":-540,"elapsed":350160,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"9749777d-0577-43a3-d1d3-42802d53ca10"},"source":["Y = []\n","for i, like in tqdm(zip(range(N_OBJ_IDS), train['likes'])):\n","  obj_id = unique_object_ids[i]\n","  if obj_id not in unique_palette_obj:\n","      continue\n","  Y.append([like]*N_IMAGES_FOR_OBJ_ID)\n","Y = np.ravel(Y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["12026it [00:06, 1931.07it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PsDFJaswMDMz"},"source":["X = train_X.copy()\n","X = np.array(X)\n","Y = np.array(Y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ClWahn4pFRUA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616164892245,"user_tz":-540,"elapsed":353942,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"08e5a67c-21c7-4c27-b67c-befeaabaeb72"},"source":["# trainデータとtestデータに分割\n","X_train, X_valid, y_train, y_valid = train_test_split(\n","    X,\n","    Y,\n","    random_state = 0,\n","    test_size = 0.2\n",")\n","del X,Y\n","print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape) \n","X_train = X_train.astype('float32') / 255\n","X_valid = X_valid.astype('float32') / 255\n","y_train = y_train.astype('float32')\n","y_valid = y_valid.astype('float32')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(9605, 100, 100, 3) (9605,) (2402, 100, 100, 3) (2402,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nRKP6--mnTYW"},"source":["## 学習準備"]},{"cell_type":"code","metadata":{"id":"C84j3zCmQMge","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616164896864,"user_tz":-540,"elapsed":358557,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"0523235f-33b3-4a25-8b26-e5b375a5eed3"},"source":["base_model = Xception(\n","    include_top = False,\n","    weights = \"imagenet\",\n","    input_shape = None\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nkTk75cPQSBL"},"source":["x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(1024, activation='relu')(x)\n","predictions = Dense(1)(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"plqY8_uZQcsn"},"source":["datagen = ImageDataGenerator(\n","    featurewise_center = False,\n","    samplewise_center = False,\n","    featurewise_std_normalization = False,\n","    samplewise_std_normalization = False,\n","    zca_whitening = False,\n","    rotation_range = 0,\n","    width_shift_range = 0.1,\n","    height_shift_range = 0.1,\n","    horizontal_flip = True,\n","    vertical_flip = False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mRgzRGGsQfSx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616164897070,"user_tz":-540,"elapsed":358748,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"fd6c2c16-37e9-4eca-dd6f-87c4797f369e"},"source":["# EarlyStopping\n","early_stopping = EarlyStopping(\n","    monitor = 'val_loss',\n","    patience = 10,\n","    verbose = 1\n",")\n","\n","# ModelCheckpoint\n","weights_dir = './weights/'\n","if os.path.exists(weights_dir) == False:os.mkdir(weights_dir)\n","model_checkpoint = ModelCheckpoint(\n","    weights_dir + \"val_loss{val_loss:.3f}.hdf5\",\n","    monitor = 'val_loss',\n","    verbose = 1,\n","    save_best_only = True,\n","    save_weights_only = True,\n","    period = 3\n",")\n","\n","# reduce learning rate\n","reduce_lr = ReduceLROnPlateau(\n","    monitor = 'val_loss',\n","    factor = 0.1,\n","    patience = 3,\n","    verbose = 1\n",")\n","\n","# log for TensorBoard\n","logging = TensorBoard(log_dir = \"log/\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N-TuONMUQgf8"},"source":["# RMSE\n","from keras import backend as K\n","def root_mean_squared_error(y_true, y_pred):\n","        return K.sqrt(K.mean(K.square(y_pred - y_true), axis = -1)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HArXU1sWeARv"},"source":["# RMSLE\n","from keras import backend as K\n","def root_mean_squared_log_error(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square(K.log(1+y_pred) - K.log(1+y_true))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"phwZ2uqfThfJ"},"source":["#===========================================================\n","# Metrics\n","#===========================================================\n","\n","def rmse(y_true, y_pred):\n","    return np.sqrt(mean_squared_error(y_true, y_pred))\n","\n","def rmsle(y_true, y_pred):\n","    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n","    \n","def get_score(y_true, y_pred):\n","    score = rmsle(y_true, y_pred)\n","    return score\n","\n","def custom_eval(preds, data):\n","    y_true = data.get_label()\n","    y_pred = np.where(preds > 0.5, 1, 0)\n","    metric = np.mean(y_true == y_pred)\n","    return 'accuracy', metric, True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pOMu0xlFTqMJ"},"source":["# ネットワーク定義\n","model = Model(inputs = base_model.input, outputs = predictions)\n","\n","#108層までfreeze\n","for layer in model.layers[:108]:\n","    layer.trainable = False\n","\n","    # Batch Normalizationのfreeze解除\n","    if layer.name.startswith('batch_normalization'):\n","        layer.trainable = True\n","    if layer.name.endswith('bn'):\n","        layer.trainable = True\n","\n","#109層以降、学習させる\n","for layer in model.layers[108:]:\n","    layer.trainable = True\n","\n","# layer.trainableの設定後にcompile\n","model.compile(\n","    optimizer = Adam(),\n","    loss = root_mean_squared_log_error,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5ekSLe2fim3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ln1REXrAnOif"},"source":["## 学習開始"]},{"cell_type":"code","metadata":{"id":"DCyLtq6sT45S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616165501938,"user_tz":-540,"elapsed":963593,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"ddc8c5c1-8145-4fbf-8e24-a94573606f4b"},"source":["#%%time\n","hist = model.fit_generator(\n","    datagen.flow(X_train, y_train, batch_size = 32),\n","    steps_per_epoch = X_train.shape[0] // 32,\n","    epochs = 50,\n","    validation_data = (X_valid, y_valid),\n","    callbacks = [early_stopping, reduce_lr],\n","    shuffle = True,\n","    verbose = 1\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","300/300 [==============================] - 67s 108ms/step - loss: 1.5251 - val_loss: 1.3340\n","Epoch 2/50\n","300/300 [==============================] - 31s 102ms/step - loss: 1.3761 - val_loss: 1.4701\n","Epoch 3/50\n","300/300 [==============================] - 31s 102ms/step - loss: 1.3901 - val_loss: 1.3647\n","Epoch 4/50\n","300/300 [==============================] - 30s 101ms/step - loss: 1.3244 - val_loss: 1.4795\n","\n","Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 5/50\n","300/300 [==============================] - 32s 106ms/step - loss: 1.3481 - val_loss: 1.3075\n","Epoch 6/50\n","300/300 [==============================] - 32s 106ms/step - loss: 1.2998 - val_loss: 1.3062\n","Epoch 7/50\n","300/300 [==============================] - 32s 107ms/step - loss: 1.3202 - val_loss: 1.3121\n","Epoch 8/50\n","300/300 [==============================] - 32s 106ms/step - loss: 1.2945 - val_loss: 1.2960\n","Epoch 9/50\n","300/300 [==============================] - 32s 106ms/step - loss: 1.3053 - val_loss: 1.3001\n","Epoch 10/50\n","300/300 [==============================] - 32s 105ms/step - loss: 1.3176 - val_loss: 1.3041\n","Epoch 11/50\n","300/300 [==============================] - 32s 105ms/step - loss: 1.2863 - val_loss: 1.3141\n","\n","Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 12/50\n","300/300 [==============================] - 31s 105ms/step - loss: 1.2948 - val_loss: 1.3105\n","Epoch 13/50\n","300/300 [==============================] - 31s 105ms/step - loss: 1.2697 - val_loss: 1.3053\n","Epoch 14/50\n","300/300 [==============================] - 32s 106ms/step - loss: 1.2735 - val_loss: 1.3035\n","\n","Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 15/50\n","300/300 [==============================] - 32s 106ms/step - loss: 1.2733 - val_loss: 1.3066\n","Epoch 16/50\n","300/300 [==============================] - 32s 107ms/step - loss: 1.2932 - val_loss: 1.3005\n","Epoch 17/50\n","300/300 [==============================] - 32s 107ms/step - loss: 1.2872 - val_loss: 1.3313\n","\n","Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n","Epoch 18/50\n","300/300 [==============================] - 32s 107ms/step - loss: 1.2961 - val_loss: 1.2999\n","Epoch 00018: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cZCKC5ppVHoz"},"source":["plt.figure(figsize=(18,6))\n","\n","# loss\n","plt.subplot(1, 2, 1)\n","plt.plot(hist.history[\"loss\"], label=\"loss\", marker=\"o\")\n","plt.plot(hist.history[\"val_loss\"], label=\"val_loss\", marker=\"o\")\n","#plt.yticks(np.arange())\n","#plt.xticks(np.arange())\n","plt.ylabel(\"loss\")\n","plt.xlabel(\"epoch\")\n","plt.title(\"\")\n","plt.legend(loc=\"best\")\n","plt.grid(color='gray', alpha=0.2)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X4ijpUEznZZh"},"source":["## testのデータ作成"]},{"cell_type":"code","metadata":{"id":"lx3nFh3wVLo4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616165742358,"user_tz":-540,"elapsed":1204007,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"4f2c6644-fb08-4810-9d37-5238ffef2d86"},"source":["unique_object_ids = test[\"object_id\"].unique()\n","N_IMAGES_FOR_OBJ_ID = 1\n","N_OBJ_IDS = len(unique_object_ids)\n","unique_palette_obj = new_palette[\"object_id\"].unique()\n","X_test = []\n","\n","# fig, axes = plt.subplots(nrows=N_OBJ_IDS, ncols=N_IMAGES_FOR_OBJ_ID, figsize=(25, 25))\n","for i in tqdm(range(N_OBJ_IDS)):\n","    obj_id = unique_object_ids[i]\n","    if obj_id not in unique_palette_obj:\n","      continue\n","\n","    palette_obj_id = new_palette.query(f\"object_id == '{obj_id}'\")\n","    #axes[i, 0].set_ylabel(obj_id)\n","    for j in range(N_IMAGES_FOR_OBJ_ID):\n","        generated = _create_random_image(palette_obj_id)\n","        X_test.append(generated)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 12008/12008 [04:00<00:00, 49.93it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ByouXaC3hGGO"},"source":["X_test = np.array(X_test)\n","X_test = X_test.astype('float32') / 255"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gp5yLdNThJW_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616165743423,"user_tz":-540,"elapsed":1205066,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"c18eb333-a403-4621-cb93-c5034b89bf1a"},"source":["X_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11988, 100, 100, 3)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"9b5tiweSndlP"},"source":["## 予測"]},{"cell_type":"code","metadata":{"id":"tJ-bmyZuVKqx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616165751006,"user_tz":-540,"elapsed":1212645,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"6ceab1d8-5913-44dc-cc44-289e61bbbf09"},"source":["y_pred = model.predict(X_test, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["375/375 [==============================] - 7s 18ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"33so4B5JmSAW"},"source":["y_test_pred = np.ravel(y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IiWiczm3nB-N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616165759474,"user_tz":-540,"elapsed":1221107,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"12cd006a-36f0-42f5-fd45-300b0c9bbd84"},"source":["train_X = np.array(train_X)\n","train_X = train_X.astype('float32') / 255\n","y_train_pred = model.predict(train_X, verbose=1)\n","y_train_pred = np.ravel(y_train_pred)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["376/376 [==============================] - 7s 18ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aul_ZSaGoQRS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dxode2p5oGvQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iE9E4Phaq-OL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"575s66k6kYOn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616165765943,"user_tz":-540,"elapsed":1227564,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"1ed34a18-5274-4580-f6ac-7dbd2186fc2e"},"source":["unique_train_ids = train[\"object_id\"].unique()\n","unique_test_ids = test[\"object_id\"].unique()\n","N_IMAGES_FOR_OBJ_ID = 1\n","N_OBJ_IDS = len(unique_train_ids)\n","unique_palette_obj = new_palette[\"object_id\"].unique()\n","\n","X_predict = []\n","\n","# fig, axes = plt.subplots(nrows=N_OBJ_IDS, ncols=N_IMAGES_FOR_OBJ_ID, figsize=(25, 25))\n","for i in tqdm(range(N_OBJ_IDS)):\n","    obj_id = unique_train_ids[i]\n","    if obj_id not in unique_palette_obj:\n","      continue\n","    X_predict.append(obj_id)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 12026/12026 [00:06<00:00, 1886.73it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dDv4p1h5o7ed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616165772730,"user_tz":-540,"elapsed":1234348,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"0298000a-f9ff-4206-a50f-18ba5a33b100"},"source":["unique_train_ids = train[\"object_id\"].unique()\n","unique_test_ids = test[\"object_id\"].unique()\n","N_IMAGES_FOR_OBJ_ID = 1\n","N_OBJ_IDS = len(unique_test_ids)\n","unique_palette_obj = new_palette[\"object_id\"].unique()\n","\n","X_test_predict = []\n","\n","# fig, axes = plt.subplots(nrows=N_OBJ_IDS, ncols=N_IMAGES_FOR_OBJ_ID, figsize=(25, 25))\n","for i in tqdm(range(N_OBJ_IDS)):\n","    obj_id = unique_test_ids[i]\n","    if obj_id not in unique_palette_obj:\n","      continue\n","    X_test_predict.append(obj_id)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 12008/12008 [00:06<00:00, 1894.94it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"7mv_UBgYozjm"},"source":["df_train_predict = pd.DataFrame(list(zip(X_predict, y_train_pred)), columns = ['object_id', 'pred_likes'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9M9k_VcBrLvh","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1616165772744,"user_tz":-540,"elapsed":1234350,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"0ac50692-dc22-4b74-ed56-73eb6f4eadfd"},"source":["df_train_predict"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>object_id</th>\n","      <th>pred_likes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0011d6be41612ec9eae3</td>\n","      <td>30.471176</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0012765f7a97ccc3e9e9</td>\n","      <td>1.910035</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00181d86ff1a7b95864e</td>\n","      <td>82.239296</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>001c52ae28ec106d9cd5</td>\n","      <td>84.744156</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>001f4c71b4d53497b531</td>\n","      <td>1.595925</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12002</th>\n","      <td>ffedf8af4fd5b3873164</td>\n","      <td>3.066441</td>\n","    </tr>\n","    <tr>\n","      <th>12003</th>\n","      <td>ffee34705ea44e1a0f79</td>\n","      <td>1.455457</td>\n","    </tr>\n","    <tr>\n","      <th>12004</th>\n","      <td>ffefbe1faf771aa4f790</td>\n","      <td>1.833020</td>\n","    </tr>\n","    <tr>\n","      <th>12005</th>\n","      <td>fff08e76cbb969eaddc7</td>\n","      <td>2.040512</td>\n","    </tr>\n","    <tr>\n","      <th>12006</th>\n","      <td>fff1d87d79953ddab2c6</td>\n","      <td>73.332771</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12007 rows × 2 columns</p>\n","</div>"],"text/plain":["                  object_id  pred_likes\n","0      0011d6be41612ec9eae3   30.471176\n","1      0012765f7a97ccc3e9e9    1.910035\n","2      00181d86ff1a7b95864e   82.239296\n","3      001c52ae28ec106d9cd5   84.744156\n","4      001f4c71b4d53497b531    1.595925\n","...                     ...         ...\n","12002  ffedf8af4fd5b3873164    3.066441\n","12003  ffee34705ea44e1a0f79    1.455457\n","12004  ffefbe1faf771aa4f790    1.833020\n","12005  fff08e76cbb969eaddc7    2.040512\n","12006  fff1d87d79953ddab2c6   73.332771\n","\n","[12007 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"sQLdC1FopIpj"},"source":["df_test_predict = pd.DataFrame(list(zip(X_test_predict, y_test_pred)), columns = ['object_id', 'pred_likes'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ApgUR9aErOrS","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1616165772771,"user_tz":-540,"elapsed":1234369,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"82f0a046-f76d-437e-e77f-91da25404ca7"},"source":["df_test_predict"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>object_id</th>\n","      <th>pred_likes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000405d9a5e3f49fc49d</td>\n","      <td>0.893163</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>001020bd00b149970f78</td>\n","      <td>61.201641</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00133be3ff222c9b74b0</td>\n","      <td>2.697483</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>001b2b8c9d3aa1534dfe</td>\n","      <td>1.954475</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00220cd4bfa082d2aa20</td>\n","      <td>1.581104</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11983</th>\n","      <td>fff4bbb55fd7702d294e</td>\n","      <td>1.654351</td>\n","    </tr>\n","    <tr>\n","      <th>11984</th>\n","      <td>fffbe07b997bec00e203</td>\n","      <td>1.277655</td>\n","    </tr>\n","    <tr>\n","      <th>11985</th>\n","      <td>fffd1675758205748d7f</td>\n","      <td>1.753125</td>\n","    </tr>\n","    <tr>\n","      <th>11986</th>\n","      <td>fffd43b134ba7197d890</td>\n","      <td>1.828647</td>\n","    </tr>\n","    <tr>\n","      <th>11987</th>\n","      <td>ffff22ea12d7f99cff31</td>\n","      <td>1.086725</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11988 rows × 2 columns</p>\n","</div>"],"text/plain":["                  object_id  pred_likes\n","0      000405d9a5e3f49fc49d    0.893163\n","1      001020bd00b149970f78   61.201641\n","2      00133be3ff222c9b74b0    2.697483\n","3      001b2b8c9d3aa1534dfe    1.954475\n","4      00220cd4bfa082d2aa20    1.581104\n","...                     ...         ...\n","11983  fff4bbb55fd7702d294e    1.654351\n","11984  fffbe07b997bec00e203    1.277655\n","11985  fffd1675758205748d7f    1.753125\n","11986  fffd43b134ba7197d890    1.828647\n","11987  ffff22ea12d7f99cff31    1.086725\n","\n","[11988 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"uCh982n7uhut","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616165772816,"user_tz":-540,"elapsed":1234411,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"05f8de9a-2a2e-4346-8597-d4b9d9298155"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/second_take\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tlMTtjEIr6NY"},"source":["df_train_predict.to_pickle('./model_temp/cnn_train_predict.pkl')\n","df_test_predict.to_pickle('./model_temp/cnn_test_predict.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ctLoJ0mHsinr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qabyhDJs79R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616165779473,"user_tz":-540,"elapsed":1241058,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"0d2ca4f9-bd40-4569-dc55-a19d491a6168"},"source":["Y = []\n","unique_train_ids = train[\"object_id\"].unique()\n","unique_test_ids = test[\"object_id\"].unique()\n","#N_IMAGES_FOR_OBJ_ID = 1\n","N_OBJ_IDS = len(unique_train_ids)\n","unique_palette_obj = new_palette[\"object_id\"].unique()\n","\n","for i, like in tqdm(zip(range(N_OBJ_IDS), train['likes'])):\n","  obj_id = unique_train_ids[i]\n","  if obj_id not in unique_palette_obj:\n","      continue\n","  Y.append(like)\n","#Y = np.ravel(Y)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["12026it [00:06, 1910.22it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6lyVFG7krnSY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616165779475,"user_tz":-540,"elapsed":1241057,"user":{"displayName":"亮那須田","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaTqhfvSTy1EqVpzuo0rNG7nH3hWlbmEUofpJ1=s64","userId":"00216170064212849588"}},"outputId":"feaf1e08-f12b-48c1-9f27-6cbf07638405"},"source":["get_score(y_train_pred, Y)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.3279886774229985"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"hLUIZOxRLQjN"},"source":["# 画像の表示など"]},{"cell_type":"code","metadata":{"id":"DnuxrK_XjZfy"},"source":["# unique_object_ids = new_palette[\"object_id\"].unique()\n","# N_IMAGES_FOR_OBJ_ID = 6\n","# N_OBJ_IDS = 5\n","\n","# fig, axes = plt.subplots(nrows=N_OBJ_IDS, ncols=N_IMAGES_FOR_OBJ_ID, figsize=(25, 25))\n","# for i in range(N_OBJ_IDS):\n","#     obj_id = unique_object_ids[i]\n","#     palette_obj_id = new_palette.query(f\"object_id == '{obj_id}'\")\n","#     axes[i, 0].set_ylabel(obj_id)\n","#     for j in range(N_IMAGES_FOR_OBJ_ID):\n","#         generated = _create_random_image(palette_obj_id)\n","#         axes[i, j].imshow(generated)\n","#         axes[i, j].grid(False)\n","#         axes[i, j].set_title(f\"Generated Image {j}\")\n","        \n","# plt.tight_layout()\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ily5czBBjZfz"},"source":["こうしてみてみると同じ`object_id`から生成された画像はパターンこそ違えど似ていて、異なる`object_id`どうしでははっきりと見分けることができます。この観察をうまく活かして、`palette.csv`をなんとか固定長の特徴ベクトル表現にしたい!という時に自己教師あり対照学習の利用を思いつきました。"]},{"cell_type":"markdown","metadata":{"id":"D1pW7jjhjZfz"},"source":["## 自己教師あり対照学習\n","\n","自己教師あり対照学習についてサクッと説明します。と言っても私も詳しくないのであまり大したことはお話しできません。まず自己教師あり学習についてですが、「入力データの一部に機械的に変換を施しその変換に対し不変の(invariant)な表現を学習する教師なし学習の１手法」です(間違っているかもしれません)。例えば自然言語処理をはじめとして近年世間を騒がせているBERTやその派生も「入力データの一部をマスクしてその部分を予測させる」という自己教師あり学習を行っています(Word2Vecもそうですね)。\n","\n","自己教師あり対照学習は、自己教師あり学習に含まれる一つの方法論で、入力データに変換を施した上で特徴表現を比較するようにして学習を行う手法です。例えば2020年に提案された[SimCLR](https://arxiv.org/abs/2002.05709)は画像に変換(Data Augmentation)を施し、同じ画像から由来する異なるData Augmentationがかけられた画像特徴を近づけるようにしつつ、異なる画像に由来する画像特徴から特徴空間上で反発するような制約を課すことで良い画像特徴を学習することを目指した手法です。\n","\n","![SimCLR](https://webbigdata.jp/wp-content/uploads/2020/04/illustration-of-the-proposed-SimCLR-framework.gif)"]},{"cell_type":"markdown","metadata":{"id":"HZ5gdOD1jZf0"},"source":["## `palette`に関する表現を学習する\n","\n","さて、この自己教師あり対照学習の考え方で、`palette`に関する表現を学習する方法を考えてみましょう。やり方の大枠は同じで、同じ`object_id`から生成された二つのランダム配置の画像特徴が似るように、異なる`object_id`から生成されたランダム配置の画像とは画像特徴が特徴空間上で離れるようなロスを設計してやれば良いはずです。\n","\n","![How-to-embed-palette](https://gist.githubusercontent.com/koukyo1994/072f7feb3c966cf91fb672006b6d0dd6/raw/c20b02e46d8f3d4c87bcae06b76d9de875f1168f/ColorEmbedding.png)\n","\n","このアイデアをPyTorchで実装してみます。"]},{"cell_type":"markdown","metadata":{"id":"8Wf3HS4CjZf0"},"source":["### Datasetの定義\n","\n","アンカー画像、正例、負例をそれぞれ作成するデータセットを作成します。"]},{"cell_type":"code","metadata":{"id":"Nq9jnBd3jZf0"},"source":["class ColorImageDataset(torchdata.Dataset):\n","    def __init__(self, df: pd.DataFrame, transforms=None):\n","        self.object_id = df[\"object_id\"].unique()\n","        self.df = df\n","        self.transforms = transforms\n","        \n","    def __len__(self):\n","        return len(self.object_id)\n","    \n","    def __getitem__(self, idx: int):\n","        object_id = self.object_id[idx]\n","        sample = self.df.query(f\"object_id == '{object_id}'\")[\n","            [\"ratio_int\", \"color_r\", \"color_g\", \"color_b\"]]\n","        # 負例のサンプリングを行う\n","        while True:\n","            neg_sample_id = np.random.choice(self.object_id)\n","            if neg_sample_id != object_id:\n","                break\n","        neg_sample = self.df.query(f\"object_id == '{neg_sample_id}'\")[\n","            [\"ratio_int\", \"color_r\", \"color_g\", \"color_b\"]]\n","        \n","        # アンカー画像の生成\n","        anchor = _create_random_image(sample)\n","        # 正例の生成\n","        pos = _create_random_image(sample)\n","        # 負例の生成\n","        neg = _create_random_image(neg_sample)\n","        \n","        anchor = self.transforms(image=anchor)[\"image\"]\n","        pos = self.transforms(image=pos)[\"image\"]\n","        neg = self.transforms(image=neg)[\"image\"]\n","        return anchor, pos, neg"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K4AEk6UCjZf1"},"source":["### CNNモデルの定義\n","\n","2層のCNNで学習をおこないます。出力は64次元のベクトルになります。"]},{"cell_type":"code","metadata":{"id":"E4VVxE7LjZf2"},"source":["# class CNNModel(nn.Module):\n","#     def __init__(self):\n","#         super().__init__()\n","#         self.cnn_encoder = nn.Sequential(\n","#             nn.Conv2d(3, 32, 3),\n","#             nn.ReLU(),\n","#             nn.Conv2d(32, 64, 3),\n","#             nn.ReLU())\n","\n","#     def forward(self, x):\n","#         return self.cnn_encoder(x).mean(dim=[2, 3])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"siSJi17fXY0U"},"source":["class CNNModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.cnn_encoder = nn.Sequential(\n","            nn.Conv2d(3, 32, 3),\n","            nn.Sigmoid(),\n","            nn.Conv2d(32, 64, 3),\n","            nn.Sigmoid())\n","\n","    def forward(self, x):\n","        return self.cnn_encoder(x).mean(dim=[2, 3])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SXIlNvhIjZf2"},"source":["### 損失関数の定義\n","\n","対照学習ではさまざまな損失関数が提案されているようなのですが、一旦適当な損失関数として、アンカー画像と正例のコサイン類似度を大きくしつつ、アンカー画像と負例のコサイン類似度は小さくなるような学習をおこなうことにします。"]},{"cell_type":"code","metadata":{"id":"Dda31UQBjZf2"},"source":["class ContrastiveLoss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.cos = nn.CosineSimilarity()\n","        \n","    def forward(self, anchor, pos, neg):\n","        pos_loss = 1.0 - self.cos(anchor, pos).mean(dim=0)\n","        neg_loss = self.cos(anchor, neg).mean(dim=0)\n","        return pos_loss + neg_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ckhkuX-6jZf2"},"source":["### その他学習用の用意\n","\n","Catalystを用いて学習を行うための準備をします。"]},{"cell_type":"code","metadata":{"id":"LbDjabyijZf4"},"source":["class ContrastRunner(Runner):\n","    def predict_batch(self, batch, **kwargs):\n","        return super().predict_batch(batch, **kwargs)\n","    \n","    def handle_batch(self, batch):\n","        anchor, pos, neg = batch[0], batch[1], batch[2]\n","        anchor = anchor.to(self.device)\n","        pos = pos.to(self.device)\n","        neg = neg.to(self.device)\n","        \n","        anchor_emb = self.model(anchor)\n","        pos_emb = self.model(pos)\n","        neg_emb = self.model(neg)\n","        \n","        loss = self.criterion(anchor_emb, pos_emb, neg_emb)\n","        self.batch_metrics.update({\n","            \"loss\": loss\n","        })\n","        \n","        self.input = batch\n","        if self.is_train_loader:\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J85KFBhpjZf4"},"source":["class SchedulerCallback(Callback):\n","    def __init__(self):\n","        super().__init__(CallbackOrder.Scheduler)\n","\n","    def on_loader_end(self, state: IRunner):\n","        lr = state.scheduler.get_last_lr()\n","        state.epoch_metrics[\"lr\"] = lr[0]\n","        if state.is_train_loader:\n","            state.scheduler.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4wPApR3xjZf5"},"source":["def set_seed(seed=1996):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PaW9XvVtjZf5"},"source":["OUTDIR = Path(\"../output/PaletteEmbedding\")\n","OUTDIR.mkdir(exist_ok=True, parents=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BMjhlErKjZf5"},"source":["## 学習のループ\n","\n","普通のKFoldで行います。今回は`likes`の情報を用いないためtest側に属している`object_id`も学習に用いることができます。"]},{"cell_type":"code","metadata":{"id":"67DlDe1Wu2Hq"},"source":["# MODEL_DIR = \"./model_temp\"\n","\n","# if not os.path.exists(MODEL_DIR):  # ディレクトリが存在しない場合、作成する。\n","#     os.makedirs(MODEL_DIR)\n","# checkpoint = ModelCheckpoint(\n","#     filepath=os.path.join(MODEL_DIR, \"model-{epoch:02d}.h5\"), save_best_only=True) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hRu69FRWvtjI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W5dUqpJawFRT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rPRsCiurvXn5"},"source":["# #kf = KFold(n_splits=2, random_state=1996, shuffle=True)\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# set_seed(1996)\n","\n","\n","\n","\n","# unique_obj_id = new_palette[\"object_id\"].unique()\n","# print(\"*\" * 100)\n","# #print(f\"Fold: {fold}\")\n","# print(trn_idx)\n","# print(val_idx)\n","# print(len(trn_idx))\n","# print(len(val_idx))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZwAkEwSUjZf5","outputId":"91bfb267-fe7e-46b0-ba0c-49cdd5f48986"},"source":["# kf = KFold(n_splits=2, random_state=1996, shuffle=True)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","set_seed(1996)\n","\n","\n","unique_obj_id = new_palette[\"object_id\"].unique()\n","\n","permutation = np.random.permutation(len(unique_obj_id))\n","trn_idx = sorted(permutation[len(unique_obj_id)//2:])\n","val_idx = sorted(permutation[:len(unique_obj_id)//2])\n","\n","\n","#for fold, (trn_idx, val_idx) in enumerate(kf.split(unique_obj_id)):\n","print(\"*\" * 100)\n","#print(f\"Fold: {fold}\")\n","\n","trn_obj_id = unique_obj_id[trn_idx]\n","val_obj_id = unique_obj_id[val_idx]\n","\n","\n","trn_palette = new_palette[\n","    new_palette[\"object_id\"].isin(trn_obj_id)\n","].reset_index(drop=True)\n","val_palette = new_palette[\n","    new_palette[\"object_id\"].isin(val_obj_id)\n","].reset_index(drop=True)\n","\n","transforms = A.Compose([A.Normalize(), ToTensorV2()])\n","trn_dataset = ColorImageDataset(trn_palette, transforms)\n","val_dataset = ColorImageDataset(val_palette, transforms)\n","\n","trn_loader = torchdata.DataLoader(\n","    trn_dataset, batch_size=128, shuffle=True, num_workers=20)\n","val_loader = torchdata.DataLoader(\n","    val_dataset, batch_size=256, shuffle=False, num_workers=20)\n","\n","model = CNNModel().to(device)\n","criterion = ContrastiveLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n","callbacks = [SchedulerCallback()]\n","#callbacks = [checkpoint]\n","runner = ContrastRunner(engine = device)\n","runner.train(model=model,\n","              criterion=criterion,\n","              optimizer=optimizer,\n","              scheduler=scheduler,\n","              callbacks=callbacks,\n","              loaders={\"train\": trn_loader, \"valid\": val_loader},\n","              num_epochs=20,\n","              # logdir=OUTDIR,\n","              # verbose=True\n","             )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["****************************************************************************************************\n","Hparams (experiment): {}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gHBC7gXWjZf6"},"source":["## 学習された特徴表現を得る\n","\n","さて、学習が済んだので今度は学習された特徴表現ベクトルを`object_id`ごとに得ます。"]},{"cell_type":"code","metadata":{"id":"ODL6W4lkrNtf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wBVww2Ffp8k"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1wAj0hI0jQQa"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t9cH-6IGkUa0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"39ElUSTqMZ9G"},"source":["#kf = KFold(n_splits=5, random_state=1213, shuffle=True)\n","embeddings = []\n","object_ids = []\n","#for fold, (_, val_idx) in enumerate(kf.split(unique_obj_id)):\n","fold = 0\n","trn_obj_id = unique_obj_id[trn_idx]\n","trn_palette = new_palette[\n","    new_palette[\"object_id\"].isin(trn_obj_id)\n","].reset_index(drop=True)\n","trn_dataset = ColorImageDataset(trn_palette, transforms)\n","object_ids.extend(trn_dataset.object_id.tolist())\n","\n","trn_loader = torchdata.DataLoader(trn_dataset, batch_size=256, shuffle=False, num_workers=20)\n","model = CNNModel()\n","ckpt = torch.load(OUTDIR / f\"fold{fold}/checkpoints/best.pth\")\n","model.load_state_dict(ckpt[\"model_state_dict\"])\n","model.to(device)\n","model.eval()\n","# アンカー画像にのみ推論\n","for anchor, _, _ in tqdm(trn_loader):\n","    anchor = anchor.to(device)\n","    with torch.no_grad():\n","        embedding = model(anchor).detach().cpu().numpy()\n","    embeddings.append(embedding)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uky2PSFPOSU1"},"source":["all_embeddings = np.concatenate(embeddings, axis=0)\n","len(all_embeddings), len(object_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjoWCqzHOULe"},"source":["embedding_df_train = pd.DataFrame(all_embeddings, \n","                            columns=[f\"color_embedding_{i}\" for i in range(len(all_embeddings[0]))],\n","                            index=object_ids)\n","embedding_df_train#.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uyFZVJvJjZf6"},"source":["#kf = KFold(n_splits=5, random_state=1213, shuffle=True)\n","embeddings = []\n","object_ids = []\n","#for fold, (_, val_idx) in enumerate(kf.split(unique_obj_id)):\n","fold = 0\n","val_obj_id = unique_obj_id[val_idx]\n","val_palette = new_palette[\n","    new_palette[\"object_id\"].isin(val_obj_id)\n","].reset_index(drop=True)\n","val_dataset = ColorImageDataset(val_palette, transforms)\n","object_ids.extend(val_dataset.object_id.tolist())\n","\n","val_loader = torchdata.DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=20)\n","model = CNNModel()\n","ckpt = torch.load(OUTDIR / f\"fold{fold}/checkpoints/best.pth\")\n","model.load_state_dict(ckpt[\"model_state_dict\"])\n","model.to(device)\n","model.eval()\n","# アンカー画像にのみ推論\n","for anchor, _, _ in tqdm(val_loader):\n","    anchor = anchor.to(device)\n","    with torch.no_grad():\n","        embedding = model(anchor).detach().cpu().numpy()\n","    embeddings.append(embedding)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IhLDb4oQjZf7"},"source":["all_embeddings = np.concatenate(embeddings, axis=0)\n","len(all_embeddings), len(object_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r5xccwU7jZf7"},"source":["embedding_df_valid = pd.DataFrame(all_embeddings, \n","                            columns=[f\"color_embedding_{i}\" for i in range(len(all_embeddings[0]))],\n","                            index=object_ids)\n","embedding_df_valid#.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pnj7Wp7vJB1H"},"source":["embedding_df = pd.concat([embedding_df_train, embedding_df_valid])\n","embedding_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tRjkTw1oS3Jn"},"source":["embedding_df.to_pickle('./model_temp/palette_embedding999.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AY_Xxy4MTDBx"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lpX4qYJnJyKQ"},"source":["palette[['object_id']].nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xux9YRoijZf8"},"source":["特徴表現が得られていることがわかります。"]},{"cell_type":"markdown","metadata":{"id":"mLGSNTU0jZf8"},"source":["## UMAPで圧縮しlikesと相関がありそうかみてみる\n","\n","得られた特徴表現が役立ちそうかみてみましょう。"]},{"cell_type":"code","metadata":{"id":"JvqZOeEcjZf8"},"source":["reducer = umap.UMAP(random_state=42)\n","reduced = reducer.fit_transform(embedding_df.values)\n","umap_df = pd.DataFrame(reduced, columns=[\"dim0\", \"dim1\"], index=embedding_df.index)\n","umap_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cepIKcbajZf8"},"source":["train = pd.read_csv(DATADIR / \"train.csv\")\n","train[\"likes\"] = np.log1p(train[\"likes\"])\n","likes_df = train[[\"object_id\", \"likes\"]]\n","likes_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BUq8XrMljZf9"},"source":["likes_df = likes_df.merge(umap_df, left_on=\"object_id\", right_index=True, how=\"left\")\n","likes_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VrSQrKPqjZf9"},"source":["plt.figure(figsize=(10, 10))\n","sns.scatterplot(x=\"dim0\", y=\"dim1\", hue=\"likes\", data=likes_df, alpha=0.5);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rRdXlTyEjZf9"},"source":["どうやら`likes`が多いサンプルは一部に集まっているようです。特徴として使えるかもしれません。"]},{"cell_type":"code","metadata":{"id":"NEBeHNiOjZf9"},"source":["# 得られた表現を保存する\n","# embedding_df.reset_index(),rename(columns={\"index\": \"object_id\"}).to_csv(\"../input/palette_embedding.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6XN2_iWBjZf9"},"source":["## 議論と考察\n","\n","ここでは上の実験に関していくつか改善できる点をあげたり、どのような学習がなされていそうかといった考察を行います。\n","\n","まず、上の実装に関してですがいくつか問題があります(私が実際サブミットに使ったものと一貫性を取りたかったためあえてそのままにしています)。\n","\n","* 上の実装ではKFoldでFoldを切って学習をしているがこれをやらない方がいい可能性がある\n","\n","わざわざKFoldを切って学習をしているのですが、これはうっかり惰性でやってしまっただけで本来必要はありません。というかおそらくやってしまうとあまり良くありません。なぜかというと、各foldで学習されたモデルはそれぞれ**違う特徴空間への射影を学習している**ため、後で特徴として利用しようとするときには5つの異なる特徴空間を無理やりくっつけたような特徴空間になってしまうからです。当然異なる特徴空間どうしでは近いか遠いかを区別できないため問題が生じます。解決策としてはKFoldを切らず、全データを用いて学習をする、ということが挙げられます。今回は特にターゲットの値を使って学習をしているわけではないのでリークの心配はありません。\n","\n","* 最終層がReLU()をかけた出力になっている\n","\n","得られた特徴表現が非常にスパースになっていることに気づいた方も多いかと思いますが、これは私がうっかりReLU()の出力を出してしまっていて負値を全て0にしてしまっているからです。これもうっかりミスでやってしまっているので直した方がいいかもしれません。\n","\n","以上の2点が実装上のミスで出てしまっている問題点のため、直すことで改善が見込めるかもしれません。\n","\n","\n","また、上記の学習プロセスで何を学習させているのか、ということを考察すると、改善の余地が見つかるかもしれません。損失関数に関して一つ考察を述べておこうと思います。まず、Anchorと正例の間のコサイン類似度を大きくするように学習する点は、色の配置に関する不変性を学習させていることに相当します(permutation invariance)。つまり色を表すタイルの配置に意味はない、という点を明示的に損失として与えています。一方、Anchorと負例の間のコサイン類似度を小さくする損失は異なるソースからでたデータをが特徴空間上で異なるような制約になっていますが、この制約は例えば色の比率やコントラストなどに関して明示的には制約をかけていないため、ひょっとすると平均色の違いを学習しているだけになっている可能性もあります。このようなことを考えると以下のような改善法があり得るかもしれません。\n","\n","* 損失関数の変更\n","\n","今回は単純にコサイン類似度のみを用いていますが、この部分に関してどのあたりに注目して欲しいかという気持ちを込めて変更できるといいかもしれません。\n","\n","* Data Augmentationの適用\n","\n","今回は正例としてAnchorと配置が違うだけの画像、負例としてAnchorと異なる画像を用いていますが、例えば負例としてAnchorの画像の色に関して変動を加えた画像を用いる、なども考えられます。\n","\n","さらに、今回はあえて画像の入力として2D CNNを適用してみましたが、そもそも色の比率のみが問題とすると実は1D(色の3ch分を数えると2D)の点列として考えて同じような学習を行う、なども改善案としてはあります。この場合には2DCNNではなく、1DCNNやTransformerなどを用いることが考えられます。\n","\n","いずれにせよ今回の実験はかなり改善の余地があるため、興味ドリブンでやってみたよ、くらいのノリだと思ってください。"]},{"cell_type":"markdown","metadata":{"id":"M0DswFjTjZf-"},"source":["## EOF"]}]}